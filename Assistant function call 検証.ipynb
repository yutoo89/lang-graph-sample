{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5a22044-d4c9-449a-8782-0bb188cc411d",
   "metadata": {},
   "source": [
    "# Function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd2ea873-bef9-4bc8-b99c-9b5715b1a195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from langsmith import wrappers, traceable\n",
    "\n",
    "# from openai import OpenAI\n",
    "# client = OpenAI()\n",
    "client = wrappers.wrap_openai(openai.Client())\n",
    "# client = wrappers.wrap_openai(OpenAI())\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "name=\"Math Tutor\",\n",
    "instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n",
    "tools=[{\"type\": \"code_interpreter\"}],\n",
    "model=\"gpt-4o-mini\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd629056-2c2b-4753-8e64-ddb47300a130",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e1f9c50-fe98-43be-9294-fcf19fc8519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "thread_id=thread.id,\n",
    "role=\"user\",\n",
    "content=\"I need to solve the equation `3x + 11 = 14`. Can you help me?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "687e2d66-8b2a-415f-92dc-f4d999ba36b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant > code_interpreter\n",
      "\n",
      "import sympy as sp\n",
      "\n",
      "# Define the variable and the equation\n",
      "x = sp.symbols('x')\n",
      "equation = sp.Eq(3*x + 11, 14)\n",
      "\n",
      "# Solve the equation\n",
      "solution = sp.solve(equation, x)\n",
      "solution\n",
      "The solution to the equation \\( 3x + 11 = 14 \\) is \\( x = 1 \\)."
     ]
    }
   ],
   "source": [
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler\n",
    "\n",
    "# First, we create a EventHandler class to define\n",
    "# how we want to handle the events in the response stream.\n",
    "\n",
    "class EventHandler(AssistantEventHandler):    \n",
    "    @override\n",
    "    def on_text_created(self, text) -> None:\n",
    "      print(f\"\\nassistant > \", end=\"\", flush=True)\n",
    "        \n",
    "    @override\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "      print(delta.value, end=\"\", flush=True)\n",
    "        \n",
    "    def on_tool_call_created(self, tool_call):\n",
    "      print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
    "    \n",
    "    def on_tool_call_delta(self, delta, snapshot):\n",
    "      if delta.type == 'code_interpreter':\n",
    "        if delta.code_interpreter.input:\n",
    "          print(delta.code_interpreter.input, end=\"\", flush=True)\n",
    "        if delta.code_interpreter.outputs:\n",
    "          print(f\"\\n\\noutput >\", flush=True)\n",
    "          for output in delta.code_interpreter.outputs:\n",
    "            if output.type == \"logs\":\n",
    "              print(f\"\\n{output.logs}\", flush=True)\n",
    "\n",
    "# Then, we use the `stream` SDK helper \n",
    "# with the `EventHandler` class to create the Run \n",
    "# and stream the response.\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    instructions=\"Please address the user as Jane Doe. The user has a premium account.\",\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dcf7fb-c8c1-4056-9f7d-ea70666d2869",
   "metadata": {},
   "source": [
    "# Assistants fundtion calling\n",
    "\n",
    "https://platform.openai.com/docs/assistants/tools/function-calling\n",
    "\n",
    "https://docs.smith.langchain.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8a8092f-a629-42ce-b5f9-b06c228c1207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today in San Francisco, the temperature is 57°F. The likelihood of rain is only 6%.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from langsmith import wrappers, traceable\n",
    "\n",
    "# client = OpenAI()\n",
    "client = wrappers.wrap_openai(openai.Client())\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    instructions=\"You are a weather bot. Use the provided functions to answer questions.\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_current_temperature\",\n",
    "                \"description\": \"Get the current temperature for a specific location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The city and state, e.g., San Francisco, CA\",\n",
    "                        },\n",
    "                        \"unit\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"enum\": [\"Celsius\", \"Fahrenheit\"],\n",
    "                            \"description\": \"The temperature unit to use. Infer this from the user's location.\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"location\", \"unit\"],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_rain_probability\",\n",
    "                \"description\": \"Get the probability of rain for a specific location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The city and state, e.g., San Francisco, CA\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"location\"],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create()\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"What's the weather in San Francisco today and the likelihood it'll rain?\",\n",
    ")\n",
    "\n",
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler\n",
    "\n",
    "\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    @override\n",
    "    def on_event(self, event):\n",
    "        # Retrieve events that are denoted with 'requires_action'\n",
    "        # since these will have our tool_calls\n",
    "        if event.event == \"thread.run.requires_action\":\n",
    "            run_id = event.data.id  # Retrieve the run ID from the event data\n",
    "            self.handle_requires_action(event.data, run_id)\n",
    "\n",
    "    def handle_requires_action(self, data, run_id):\n",
    "        tool_outputs = []\n",
    "\n",
    "        for tool in data.required_action.submit_tool_outputs.tool_calls:\n",
    "            if tool.function.name == \"get_current_temperature\":\n",
    "                tool_outputs.append({\"tool_call_id\": tool.id, \"output\": \"57\"})\n",
    "            elif tool.function.name == \"get_rain_probability\":\n",
    "                tool_outputs.append({\"tool_call_id\": tool.id, \"output\": \"0.06\"})\n",
    "\n",
    "        # Submit all tool_outputs at the same time\n",
    "        self.submit_tool_outputs(tool_outputs, run_id)\n",
    "\n",
    "    def submit_tool_outputs(self, tool_outputs, run_id):\n",
    "        # Use the submit_tool_outputs_stream helper\n",
    "        with client.beta.threads.runs.submit_tool_outputs_stream(\n",
    "            thread_id=self.current_run.thread_id,\n",
    "            run_id=self.current_run.id,\n",
    "            tool_outputs=tool_outputs,\n",
    "            event_handler=EventHandler(),\n",
    "        ) as stream:\n",
    "            for text in stream.text_deltas:\n",
    "                print(text, end=\"\", flush=True)\n",
    "            print()\n",
    "\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id, assistant_id=assistant.id, event_handler=EventHandler()\n",
    ") as stream:\n",
    "    stream.until_done()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1ab3c4c-6940-4495-862d-1d375c47c767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function_name: fetch_store_ratings\n",
      "args: {}\n",
      "function_name: fetch_store_data\n",
      "args: {'store_id': 8}\n",
      "評価が最も高い店舗は「ムブレストラン」で、評価は4.9です。店舗の所在地は東京都です。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from langsmith import wrappers, traceable\n",
    "\n",
    "# client = OpenAI()\n",
    "client = wrappers.wrap_openai(openai.Client())\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    instructions=\"あなたは店舗運営とデータ分析のスペシャリストです。店舗管理者の相談に答えてください。\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"fetch_store_ratings\",\n",
    "                \"description\": \"Fetch store ratings for all stores. Returns: dict: A dictionary where keys are store IDs and values are ratings (1.0 to 5.0).\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {},\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"fetch_store_data\",\n",
    "                \"description\": \"Fetch store information for the specified store ID.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"store_id\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"description\": \"店舗ID\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"store_id\"],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create()\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"評価が最も高い店舗を調査し、その店舗名を教えてください。\",\n",
    ")\n",
    "\n",
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler\n",
    "import json\n",
    "\n",
    "\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    @override\n",
    "    def on_event(self, event):\n",
    "        # Retrieve events that are denoted with 'requires_action'\n",
    "        # since these will have our tool_calls\n",
    "        if event.event == \"thread.run.requires_action\":\n",
    "            run_id = event.data.id  # Retrieve the run ID from the event data\n",
    "            self.handle_requires_action(event.data, run_id)\n",
    "\n",
    "    def handle_requires_action(self, data, run_id):\n",
    "        tool_outputs = []\n",
    "\n",
    "        for tool in data.required_action.submit_tool_outputs.tool_calls:\n",
    "            args = json.loads(tool.function.arguments)\n",
    "            print(f\"function_name: {tool.function.name}\")\n",
    "            print(f\"args: {args}\")\n",
    "            if tool.function.name == \"fetch_store_ratings\":\n",
    "                output = {\n",
    "                    \"1\": 1.3,\n",
    "                    \"2\": 4.0,\n",
    "                    \"3\": 1.0,\n",
    "                    \"4\": 3.5,\n",
    "                    \"5\": 3.6,\n",
    "                    \"6\": 3.9,\n",
    "                    \"7\": 3.5,\n",
    "                    \"8\": 4.9,\n",
    "                    \"9\": 3.4,\n",
    "                    \"10\": 2.0,\n",
    "                }\n",
    "                output = json.dumps(output)\n",
    "                tool_outputs.append({\"tool_call_id\": tool.id, \"output\": output})\n",
    "            elif tool.function.name == \"fetch_store_data\":\n",
    "                output = {\"id\": 8, \"name\": \"モブレストラン\", \"locale\": \"東京\"}\n",
    "                output = json.dumps(output)\n",
    "                tool_outputs.append({\"tool_call_id\": tool.id, \"output\": output})\n",
    "\n",
    "        # Submit all tool_outputs at the same time\n",
    "        self.submit_tool_outputs(tool_outputs, run_id)\n",
    "\n",
    "    def submit_tool_outputs(self, tool_outputs, run_id):\n",
    "        # Use the submit_tool_outputs_stream helper\n",
    "        with client.beta.threads.runs.submit_tool_outputs_stream(\n",
    "            thread_id=self.current_run.thread_id,\n",
    "            run_id=self.current_run.id,\n",
    "            tool_outputs=tool_outputs,\n",
    "            event_handler=EventHandler(),\n",
    "        ) as stream:\n",
    "            for text in stream.text_deltas:\n",
    "                print(text, end=\"\", flush=True)\n",
    "            print()\n",
    "\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id, assistant_id=assistant.id, event_handler=EventHandler()\n",
    ") as stream:\n",
    "    stream.until_done()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f09c2c7-1610-473f-b42a-719283b4e7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "はい、あなたの質問は「評価が最も高い店舗を調査し、その店舗名を教えてください。」でした。最も高い評価の店舗は「ムブレストラン」で、評価は4.9です。何か他にお手伝いできることはありますか？\n"
     ]
    }
   ],
   "source": [
    "client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"わたしのさっきの質問を覚えていますか？\"\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    ")\n",
    "\n",
    "if run.status == \"completed\":\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "    print(messages.data[0].content[0].text.value)\n",
    "else:\n",
    "    print(run.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "584d6778-e72a-4ac4-84d9-2b67d81e355e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'はい、あなたの質問は「評価が最も高い店舗を調査し、その店舗名を教えてください。」でした。最も高い評価の店舗は「ムブレストラン」で、評価は4.9です。何か他にお手伝いできることはありますか？'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.data[0].content[0].text.value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
